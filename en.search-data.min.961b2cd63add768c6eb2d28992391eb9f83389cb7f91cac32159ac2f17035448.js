'use strict';(function(){const b={cache:!0};b.doc={id:'id',field:['title','content'],store:['title','href','section']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/docs/defenses/design-protections/',title:"Application Design",section:"Defense Mechanisms",content:"Application Design #  This section contains articles explaining how you can:\n Defend against cache probing attacks, see Cache Protections. Protect especially sensitive endpoints, see Subresource Protections.  "}),a.add({id:1,href:'/docs/defenses/isolation-policies/resource-isolation/',title:"Resource Isolation Policy",section:"Isolation Policies",content:"Resource Isolation Policy prevents external websites from requesting your resources. Blocking such traffic mitigates common web vulnerabilities such as CSRF, XSSI, or XS-Leaks. The policy can be enabled for applications whose endpoints are not intended to be loaded in a cross-site context and will allow resource requests coming from your application as well as direct navigations.\nImplementation with Fetch Metadata #  The below snippet showcases an example implemention of the Resource Isolation Policy with the use of Fetch Metadata headers:\n# Reject cross-origin requests to protect from , XSSI, XS-Leaks, and other bugs def allow_request(req): # [OPTIONAL] Exempt paths/endpoints meant to be served cross-origin. if req.path in (\u0026#39;/my_CORS_endpoint\u0026#39;, \u0026#39;/favicon.png\u0026#39;): return True # Safe to set `Cross-Origin-Resource-Policy: same-site`. (see Considerations) # Allow requests from browsers which don\u0026#39;t send Fetch Metadata if not req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-site\u0026#39;]: return True # Allow same-site and browser-initiated requests if req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-site\u0026#39;] in (\u0026#39;same-origin\u0026#39;, \u0026#39;same-site\u0026#39;, \u0026#39;none\u0026#39;): return True # Allow simple top-level navigations, this includes embeds if req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-mode\u0026#39;] == \u0026#39;navigate\u0026#39; and req.method == \u0026#39;GET\u0026#39;: return True # Reject all other requests return False Considerations #  It should be safe to set a Cross-Origin-Resource-Policy: same-site response header on all requests that have not explicitly been exempted from Resource Isolation Policy. See CORP.\nDeployment #  Check out this web.dev article to learn more about this protection, some different policies, and tips on how to deploy it.\n"}),a.add({id:2,href:'/docs/attacks/timing-attacks/clocks/',title:"Clocks",section:"Timing Attacks",content:"We can distinguish two types of clocks ‚Äì explicit and implicit. Explicit clocks are used by developers to get direct timing measurements, mechanisms of this type are offered explicitly by the browser. In contrast, implicit clocks utilize particular web features to create unintended clocks that allow measuring the relative passage of time.\nExplicit Clocks #  performance.now API #  The performance.now() API allows developers to get high-resolution timing measurements.\n info\nIn order to mitigate some types of XS-Leaks, performance.now()\u0026rsquo;s accuracy was reduced from a range of nanoseconds to microsecond precision in all modern browsers 1 2 3.\n  Reduce resolution of performance.now (Webkit). link \u0026#x21a9;\u0026#xfe0e;\n Reduce precision of performance.now() to 20us (Gecko). link \u0026#x21a9;\u0026#xfe0e;\n Reduce resolution of performance.now to prevent timing attacks (Blink). link \u0026#x21a9;\u0026#xfe0e;\n    Date API #  The Date API is the oldest API present in browsers which can be used to obtain timing measurements. It allows developers to get dates, and get Unix timestamps with Date.now(). These measurements are much less precise than performance.now(). Before the introduction of newer APIs, attacks used to leverage this API 1.\nImplicit Clocks #  SharedArrayBuffer and Web Workers #  With the introduction of Web Workers, new mechanisms to exchange data between threads were created 2. One of those mechanisms is SharedArrayBuffer which provides memory sharing between the main thread and a worker thread. A malicious website can create an implicit clock by loading a worker running an infinite loop that increments a number in the buffer. This value can then be accessed by the main thread at any time to read how many incrementations were performed.\n info\nSharedArrayBuffer was removed from browsers with the publication of Spectre. It was reintroduced later in 2020, requiring documents to be in a secure context to make use of the API. Since secure contexts cannot reference any cross-origin content that has not explicitly opted in to being accessed, this means SharedArrayBuffers cannot be used as clocks for some XS-Leaks.\nTo make use of SharedArrayBuffer in modern browsers, an application needs to explicitly opt in to COOP and COEP by setting the following headers:\nCross-Origin-Opener-Policy: same-origin Cross-Origin-Embedder-Policy: require-corp   // Define a function to be ran inside a WebWorker function worker_function() { self.onmessage = function (event) { const sharedBuffer = event.data; const sharedArray = new Uint32Array(sharedBuffer); // Infinitely increase the uint32 number  while (true) Atomics.add(sharedArray, 0, 1); }; } // Create the WebWorker from the JS function and invoke it const worker = new Worker( URL.createObjectURL( new Blob([`(${worker_function})()`], { type: \u0026#34;text/javascript\u0026#34; })) ); // Create a Shared buffer between the WebWorker and a document const sharedBuffer = new SharedArrayBuffer(Uint32Array.BYTES_PER_ELEMENT); const sharedArray = new Uint32Array(sharedBuffer); worker.postMessage(sharedBuffer);   tip\nTo get the relative time in a main thread, you can use the Atomics API.\nAtomics.load(sharedArray, 0);   Other Clocks #  There are a considerable number of APIs attackers can abuse to create implicit clocks: Broadcast Channel API, Message Channel API, requestAnimationFrame, setTimeout, CSS animations, and others 3 4.\nReferences #    Exposing Private Information by Timing Web Applications, link \u0026#x21a9;\u0026#xfe0e;\n Shared memory: Side-channel information leaks, link \u0026#x21a9;\u0026#xfe0e;\n Fantastic Timers and Where to Find Them: High-Resolution Microarchitectural Attacks in JavaScript, link \u0026#x21a9;\u0026#xfe0e;\n Trusted Browsers for Uncertain Times, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:3,href:'/docs/attacks/xs-search/',title:"XS-Search",section:"Attacks",content:"Cross-site search (XS-Search) is an important attack principle in the family of XS-Leaks. This type of attack abuses Query-Based Search Systems to leak user information from an attacker origin 1 2. The original attack uses timing measurements to detect whether or not a search system returns results and works as follows:\n Establish a baseline of the time needed for a request to return results (hit), and a baseline for the time needed by a request with no results (miss). Start a timing attack on the request to the search endpoint, brute-forcing the first character (?q=r). If the measurement is under the hit baseline, then add one more character (?q=ra); otherwise try a new one (?q=s). In the end, a full secret (?q=secret) can be leaked.  This attack requires multiple timing measurements to be accurate, something which can be improved with inflation techniques and statistical analysis. Furthermore, instead of brute-forcing letter by letter, attackers can search specific words or sentences to leak only the occurrence of results.\nThe most important part of this attack is its principle, as it can be applied to a number of different XS-Leaks.\nInflation Techniques #  The inflation techniques of XS-Search are used to increase the accuracy of the attack to make the two response types (hit or miss) easier to distinguish. The following two mechanisms allow attackers to make better measurements:\n If a search system reflects certain GET parameters into the response when returning results, the size of the response increases. This makes the request more distinguishable because the time to prepare the response and send it over the network grows substantially. Force the server to perform more computation work before returning a response. This approach can be applied in search systems offering more expressive query languages (e.g. exclude terms in Gmail needs to process every character in the results).  Extended Principle #  While the original research around XS-Search focused on timing attacks, the principle of the attack extends to other XS-Leaks. Instead of relying on timing measurements, which are unreliable, attackers can use other XS-Leaks to extract the same information.\nIn a Query-Based Search System, a user submits queries and gets responses associated with those queries. This action can result in two different outcomes:\n The system shows results and the page behaves in a specific way (first state). The system does not show results and the page behaves in a different way than in step 1 (second state).  If both behaviors above can be distinguished by a more reliable XS-Leak than timing, then an attacker could perform a more efficient XS-Search attack. For example, if the number of frames on a page varies based on search results (step 1 and 2 are distinguishable), this attack principle can be applied with a Frame Counting XS-Leak which could be more accurate than one using timing measurements.\nDefense #     Attack Alternative SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     XS-Search (timing) ‚úîÔ∏è ‚ùå ‚ùå RIP üîó NIP    üîó ‚Äì Defense mechanisms must be combined to be effective against different scenarios.\nReferences #    Cross-Site Search Attacks, link \u0026#x21a9;\u0026#xfe0e;\n Cross-Site Search (XS-Search) Attacks - Hemi Leibowitz, OWASP AppSec IL 2015, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:5,href:'/docs/defenses/opt-in/',title:"Opt-In Mechanisms",section:"Defense Mechanisms",content:"Opt-In Mechanisms #  There are many different opt-in mechanisms that applications can deploy to defend against XS-Leaks. Note that mechanisms can overlap in terms of the techniques they defend against.\n Fetch Metadata allows the application to determine how and why a request was initiated so that it can choose to reject any malicious requests. Cross-Origin-Opener-Policy allows an application to prevent other websites from interacting with it via window.open or window.opener. Cross-Origin-Resource-Policy allows an application to prevent other sites from including specific resources. Framing Protections allow an application to define what sites are allowed to frame it. SameSite Cookies allow an application to determine which requests from third party sites can include cookies.  "}),a.add({id:6,href:'/docs/defenses/isolation-policies/framing-isolation/',title:"Framing Isolation Policy",section:"Isolation Policies",content:"Framing Isolation Policy is a stricter version of Framing Protections where the request gets blocked at the application level rather than by the browser. This is designed to protect against various attacks (e.g. XSSI, CSRF, XS-Leaks) by blocking framing requests to endpoints that are not intended to be framable.\nIt can be combined with Resource Isolation Policy to effectively tighten the attack surface within cross-site information leaks.\n tip\nInstead of rejecting all non-framable endpoints, the user could be prompted to confirm the action, e.g. Confirm that you visited this page from a trusted origin, to mitigate the risk of attacks in the background, and, at the same time, help prevent unintended breakages of an application.   tip\nWhen deployed together with Resource Isolation Policy, Framing Isolation Policy does not protect against leaks utilizing window references (e.g. window.length), so other navigational protections such as COOP or Navigation Isolation Policy can be helpful.  Implementation with Fetch Metadata #  The below snippet showcases an example implemention of the Framing Isolation Policy by an application:\n# Reject cross-site requests to protect from CSRF, XSSI, XS-Leaks, and other bugs def allow_request(req): # Allow requests from browsers which don\u0026#39;t send Fetch Metadata if not req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-site\u0026#39;]: return True if not req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-mode\u0026#39;]: return True if not req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-dest\u0026#39;]: return True # Allow non-navigational requests if req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-mode\u0026#39;] not in (\u0026#39;navigate\u0026#39;, \u0026#39;nested-navigate\u0026#39;): return True # Allow requests not originated from embeddable elements if req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-dest\u0026#39;] not in (\u0026#39;frame\u0026#39;, \u0026#39;iframe\u0026#39;, \u0026#39;embed\u0026#39;, \u0026#39;object\u0026#39;): return True # [OPTIONAL] Exempt paths/endpoints meant to be served cross-site. if req.path in (\u0026#39;/my_frame_ancestors_host_src\u0026#39;): return True # Reject all other requests return False Considerations #  Framing Isolation Policy cannot be applied if an endpoint allows framing requests from specific origins via X-Frame-Options and/or Content Security Policy\u0026rsquo;s frame-ancestors directive.\n"}),a.add({id:7,href:'/docs/attacks/window-references/',title:"Window References",section:"Attacks",content:"If a page sets its opener property to null or is using COOP protection depending on the users' state, it becomes possible to infer cross-site information about that state. For example, attackers can detect whether a user is logged in by opening an endpoint in an iframe (or a new window) which only authenticated users have access to, simply by checking its window reference.\nCode Snippet #  The below snippet demonstrates how to detect whether the opener property was set to null, or whether the COOP header is present with a value other than unsafe-none. This can be done with both iframes and new windows.\n// define the vulnerable URL const v_url = \u0026#39;https://example.org/profile\u0026#39;; const exploit = (url, new_window) =\u0026gt; { let win; if(new_window){ // open the url in a new tab to see if win.opener was affected by COOP  // or set to null  win = open(url); }else{ // create an iframe to detect whether the opener is defined  // won\u0026#39;t work for COOP detection, or if a page has implemented framing protections  document.body.insertAdjacentHTML(\u0026#39;beforeend\u0026#39;, \u0026#39;\u0026lt;iframe name=\u0026#34;xsleaks\u0026#34;\u0026gt;\u0026#39;); // redirect the iframe to the vulnerable URL  win = open(url, \u0026#34;xsleaks\u0026#34;); } // wait 2 seconds to let the page load  setTimeout(() =\u0026gt; { // check the opener property of the newly opened window  if(!win.opener) console.log(\u0026#34;win.opener is null\u0026#34;); else console.log(\u0026#34;win.opener is defined\u0026#34;); }, 2000); } exploit(v_url); exploit(v_url, 1); Defense #  To mitigate this type of XS-Leak, be consistent across different pages: set the opener property to the same value on all pages using COOP. Using JavaScript to set opener to null can result in edge cases because it\u0026rsquo;s possible to disable JavaScript entirely using iframe\u0026rsquo;s sandbox attribute.\n"}),a.add({id:8,href:'/docs/attacks/browser-features/corb/',title:"CORB Leaks",section:"Browser Features",content:"Cross-Origin Read Blocking (CORB) is a web platform security feature aimed at reducing the impact of speculative side-channel attacks such as Spectre. Unfortunately, blocking certain types of requests introduced a new type of XS-Leaks 1 that allows attackers to detect if CORB was enforced on one request, but wasn\u0026rsquo;t on another. Nevertheless, the introduced XS-Leaks are much less problematic than the issues actively protected by CORB (e.g. Spectre).\n info\nThis is a known issue in Chromium, and while it might remain unfixed, its impact is greatly reduced by the rollout of SameSite Cookies by default in Chromium-based browsers.  CORB \u0026amp; Error Events #  Attackers can observe when CORB is enforced if a response returns a CORB protected Content-Type (and nosniff) with the status code 2xx which results in CORB stripping the body and headers from the response. Detecting this protection allows an attacker to leak the combination of both the status code (success vs. error) and the Content-Type (protected by CORB or not). This allows the distinction of two possible states as shown in these examples:\n One state results in a request being protected by CORB and the second state in a client error (404). One state is protected by CORB and the second state is not.  The following steps allow abusing this protection in the context of the first example:\n An attacker can embed a cross-origin resource in a script tag which returns 200 OK with text/html as Content-Type and a nosniff Header. To protect sensitive contents from entering the attacker\u0026rsquo;s process, CORB will replace the original response with an empty one. Since an empty response is valid JavaScript, the onerror event won\u0026rsquo;t be fired, onload will fire instead. The attacker triggers a second request (corresponding to a second state), similar to 1., which returns something other than 200 OK. The onerror event will fire.  The interesting behavior is that CORB creates a valid resource out of the request which could contain something other than JavaScript (causing an error). Considering a non-CORB environment, both 1. and 4. requests would trigger an error. This introduces an XS-Leak as these situations are now distinguishable.\nDetecting the nosniff Header #  CORB can also allow attackers to detect when the nosniff header is present in the request. This problem originated due to the fact that CORB is only enforced depending on the presence of this header and some sniffing algorithms. The example below shows two distinguishable states:\n CORB will prevent an attacker page which embeds a resource as a script if the resource is served with text/html as Content-Type along with the nosniff header. If the resource does not set nosniff and CORB fails to infer the Content-Type of the page (which remains text/html), a SyntaxError will be fired since the contents can\u0026rsquo;t be parsed as valid JavaScript. This error can be caught by listening to window.onerror as script tags only trigger error events under certain conditions.  Defense #     SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     ‚úîÔ∏è ‚ùå ‚ùå RIP üîó NIP    üîó ‚Äì Defense mechanisms must be combined to be effective against different scenarios.\n tip\nDevelopers can deploy CORP in an application\u0026rsquo;s subresources to force a protection similar to CORB that does not inspect responses to decide when to act. To prevent attackers from abusing this XS-Leak, generic XS-Leaks defense mechanisms are also effective.  References #    CORB vs side channels, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:9,href:'/docs/attacks/browser-features/corp/',title:"CORP Leaks",section:"Browser Features",content:"Explanation #  Cross-Origin Resource Policy (CORP) is a web platform security feature that allows websites to prevent certain resources from being loaded by other origins. This protection complements CORB since it is an opt-in defense, whereas CORB blocks some cross-origin reads by default. Unfortunately, similar to CORB, applications can introduce a new XS-Leak if they misconfigure the use of this protection.\nA webpage will introduce an XS-Leak if CORP is enforced based on user data. If a page search feature enforces CORP when showing results, but doesn\u0026rsquo;t do so when returning no results, an attacker will be able to distinguish the two scenarios. This occurs because a page/resource protected by CORP will return an error when fetched cross-origin.\nDefense #  An application can avoid this XS-Leak if it guarantees CORP is deployed in all application resources/endpoints. Moreover, generic security mechanisms that allow the invalidation of cross-site requests will also help prevent this attack.\n   SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     ‚úîÔ∏è ‚ùå ‚ùå RIP üîó NIP    üîó ‚Äì Defense mechanisms must be combined to be effective against different scenarios.\n"}),a.add({id:10,href:'/docs/attacks/error-events/',title:"Error Events",section:"Attacks",content:"When a webpage issues a request to a server (e.g. fetch, HTML tags), the server receives and processes this request. When received, the server decides whether the request should succeed (e.g. 200) or fail (e.g. 404) based on the provided context. When a response has an error status, an error event is fired by the browser for the page to handle. These errors also cover situations where the parser fails, for example when trying to embed HTML content as an image.\nFor example, attackers can detect whether a user is logged in to a service by checking if the user has access to resources only available to authenticated users 1. The impact of this XS-Leak varies depending on the application, but it can lead to sophisticated attacks with the ability to deanonymize users 2.\nError events can be thrown from a large variety of HTML tags, and some behaviors vary from browser to browser 3. For instance, the behavior can depend on the loaded resources, HTML tags, presence of certain headers (e.g. nosniff, Content-Type), or the enforcement of default browser protections, etc.\nThe principle of leaking information with error events can be abstracted and applied to a variety of XS-Leaks. For example, one technique for Cache Probing uses Error Events to detect if a certain image was cached by the browser.\nCode Snippet #  The below snippet demonstrates how an Error Event can be detected with the \u0026lt;script\u0026gt; tag:\nfunction probeError(url) { let script = document.createElement(\u0026#39;script\u0026#39;); script.src = url; script.onload = () =\u0026gt; console.log(\u0026#39;Onload event triggered\u0026#39;); script.onerror = () =\u0026gt; console.log(\u0026#39;Error event triggered\u0026#39;); document.head.appendChild(script); } // because google.com/404 returns HTTP 404, the script triggers error event probeError(\u0026#39;https://google.com/404\u0026#39;); // because google.com returns HTTP 200, the script triggers onload event probeError(\u0026#39;https://google.com/\u0026#39;); Defense #  The mitigation of this XS-Leak often varies depending on how applications handle certain resources. The general approach is to adopt consistent behaviors whereever possible. In specific scenarios, applications might use Subresource Protections to prevent attackers from predicting a URL and going forward with an attack.\nFinally, without applying bigger changes in the logic of applications, generic web platform security features can be deployed to mitigate this XS-Leak at a larger scale.\n   SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     ‚úîÔ∏è ‚ùå ‚ùå RIP   \\(^{1}\\)        The resource isolation policy should be enough to prevent error-based cross-site leaks, although in some scenarios without the Framing Isolation Policy, the error events could be leaked through iframes.  Real World Example #  A bug allowed abusing a Twitter API endpoint to which only a specified user would have access. This endpoint would return an error to every Twitter user except the owner. An attacker could exploit this behavior to deanonymize a user 1. Similarly, another bug allowed abusing an image authentication mechanism of private messages to achieve the same goal 4 2.\nReferences #    Twitter ID exposure via error-based side-channel attack, link \u0026#x21a9;\u0026#xfe0e;\n Leaky Images: Targeted Privacy Attacks in the Web, link \u0026#x21a9;\u0026#xfe0e;\n Cross-Origin State Inference (COSI) Attacks: Leaking Web Site States through XS-Leaks, link (see page 6) \u0026#x21a9;\u0026#xfe0e;\n Tracking of users on third-party websites using the Twitter cookie, due to a flaw in authenticating image requests, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:11,href:'/docs/attacks/frame-counting/',title:"Frame Counting",section:"Attacks",content:"Window references allow cross-origin pages to get access to some of the attributes of other pages. These references become available when using or allowing iframe and window.open. The references provide (limited) information about the window as they still respect the same-origin policy.\nOne of the accessible attributes is window.length which provides the number of frames in the window. This attribute can provide valuable information about a page to an attacker.\nWebsites commonly use frames (or iframes) and this choice doesn\u0026rsquo;t necessarily imply security issues. There are, however, cases where a website might change the number of frames on a page depending on some user information. For example, this could happen on a page that changes its layout depending on the GET parameters and the victim\u0026rsquo;s data. It might be possible for an attacker to infer information about the victim by measuring the value of window.length on different pages.\nCode Snippet #  The below snippet demonstrates how to access the information about the number of frames on a cross-site page:\n// Get a reference to the window var win = window.open(\u0026#39;https://example.org\u0026#39;); // Wait for the page to load setTimeout(() =\u0026gt; { // Read the number of iframes loaded  console.log(\u0026#34;%d iframes detected\u0026#34;, win.length); }, 2000); Attack Alternatives #  In some cases, different application states have the same number of frames, preventing attackers from being able to distinguish them. However, continuously recording the frame count while the page is loading may show a pattern that might leak information to an attacker:\n// Get a reference to the window var win = window.open(\u0026#34;https://example.org\u0026#34;); var pattern = []; // In a loop, register the number of iframes at 60ms interval var recorder = setInterval(() =\u0026gt; { pattern.push(win.length) }, 60); // Break the loop after 6 seconds setTimeout(() =\u0026gt; { clearInterval(recorder); console.log(\u0026#34;The pattern is: %s\u0026#34;, pattern.join(\u0026#39;, \u0026#39;)); }, 6 * 1000); Case Scenarios #  Some examples of frame counting attacks are:\n A website lets a user search for user information in a search engine. If the page structure has a different number of iframes depending on whether there are results to the user query, an attacker could use the XS-Search technique to leak those secrets. A website structures the user profile page differently based on gender or other PII. An attacker can easily leak this information by opening the page and counting frames.  Defense #     Attack Alternative SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     iframes ‚úîÔ∏è ‚ùå ‚úîÔ∏è FIP   windows ‚ùå ‚úîÔ∏è ‚ùå NIP    Real World Example #  A vulnerability reported to Facebook used this technique to leak user-related information such as specific content published in posts, religious information about friends, or photo locations1.\nReferences #    Patched Facebook Vulnerability Could Have Exposed Private Information About You and Your Friends. link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:12,href:'/docs/attacks/navigations/',title:"Navigations",section:"Attacks",content:"Detecting if a cross-site page triggered a navigation (or didn\u0026rsquo;t) can be useful to an attacker. For example, a website may trigger a navigation in a certain endpoint depending on the status of the user.\nTo detect if any kind of navigation occurred, an attacker can:\n Use an iframe and count the number of times the onload event is triggered. Check the value of history.length, which is accessible through any window reference. This provides the number of entries in the history of a victim that were either changed by history.pushState or by regular navigations. To get the value of history.length, an attacker changes the location of the window reference to the target website, then changes back to same-origin, and finally reads the value.  Download Trigger #  When an endpoint sets the Content-Disposition: attachment header, it instructs the browser to download the response as an attachment instead of navigating to it. Detecting if this behavior occurred might allow attackers to leak private information if the outcome depends on the state of the victim\u0026rsquo;s account.\nDownload bar #  In Chromium-based browsers, when a file is downloaded, a preview of the download process appears in a bar at the bottom, integrated into the browser window. By monitoring the window height, attackers can detect whether the \u0026ldquo;download bar\u0026rdquo; opened:\n// Read the current height of the window var screenHeight = window.innerHeight; // Load the page that may or may not trigger the download window.open(\u0026#39;https://example.org\u0026#39;); // Wait for the tab to load setTimeout(() =\u0026gt; { // If the download bar appears, the height of all tabs will be smaller  if (window.innerHeight \u0026lt; screenHeight) { console.log(\u0026#39;Download bar detected\u0026#39;); } else { console.log(\u0026#39;Download bar not detected\u0026#39;); } }, 2000);   important\nThis attack is only possible in Chromium-based browsers with automatic downloads enabled. In addition, the attack can\u0026rsquo;t be repeated since the user needs to close the download bar for it to be measurable again.  Download Navigation (with iframes) #  Another way to test for the Content-Disposition: attachment header is to check if a navigation occurred. If a page load causes a download, it does not trigger a navigation and the window stays within the same origin.\nThe following snippet can be used to detect whether such a navigation has occurred and therefore detect a download attempt:\n// Set the destination URL to test for the download attempt var url = \u0026#39;https://example.org/\u0026#39;; // Create an outer iframe to measure onload event var iframe = document.createElement(\u0026#39;iframe\u0026#39;); document.body.appendChild(iframe); // Create an inner iframe to test for the download attempt iframe.srcdoc = `\u0026lt;iframe src=\u0026#34;${url}\u0026#34; \u0026gt;\u0026lt;/iframe\u0026gt;`; iframe.onload = () =\u0026gt; { try { // If a navigation occurs, the iframe will be cross-origin,  // so accessing \u0026#34;inner.origin\u0026#34; will throw an exception  iframe.contentWindow.frames[0].origin; console.log(\u0026#39;Download attempt detected\u0026#39;); } catch(e) { console.log(\u0026#39;No download attempt detected\u0026#39;); } }   info\nWhen there is no navigation inside an iframe caused by a download attempt, the iframe does not trigger an onload event directly. For this reason, in the example above, an outer iframe was used instead, which listens for an onload event which triggers when subresources finish loading, including iframes.   important\nThis attack works regardless of any Framing Protections, because the X-Frame-Options and Content-Security-Policy headers are ignored if Content-Disposition: attachment is specified.  Download Navigation (without iframes) #  A variation of the technique presented in the previous section can also be effectively tested using window objects:\n// Set the destination URL var url = \u0026#39;https://example.org\u0026#39;; // Get a window reference var win = window.open(url); // Wait for the window to load. setTimeout(() =\u0026gt; { try { // If a navigation occurs, the iframe will be cross-origin,  // so accessing \u0026#34;win.origin\u0026#34; will throw an exception  win.origin; parent.console.log(\u0026#39;Download attempt detected\u0026#39;); } catch(e) { parent.console.log(\u0026#39;No download attempt detected\u0026#39;); } }, 2000); Server-Side Redirects #  Inflation #  A server-side redirect can be detected from a cross-origin page if the destination URL increases in size and contains an attacker-controlled input (either in the form of a query string parameter or a path). The following technique relies on the fact that it is possible to induce an error in most web-servers by generating large request parameters/paths. Since the redirect increases the size of the URL, it can be detected by sending exactly one character less than the server\u0026rsquo;s maximum capacity. That way, if the size increases, the server will respond with an error that can be detected from a cross-origin page (e.g. via Error Events).\n example\nAn example of this attack can be seen here.  Cross-Origin Redirects #  CSP Violations #  Content-Security-Policy (CSP) is an in-depth defense mechanism against XSS and data injection attacks. When a CSP is violated, a SecurityPolicyViolationEvent is thrown. An attacker can set up a CSP which triggers a Violation event every time a fetch follows an URL not set in the CSP directive. This allows an attacker to detect if a redirect to another origin occurred 1 2.\nThe example below triggers a SecurityPolicyViolationEvent if the website set in the fetch API (line 6) redirects to a website other than target.page:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;!-- Set the Content-Security-Policy to only allow example.org --\u0026gt; \u0026lt;meta http-equiv=\u0026#34;Content-Security-Policy\u0026#34; content=\u0026#34;connect-src https://example.org\u0026#34;\u0026gt; \u0026lt;script\u0026gt; // Listen for a CSP violation event document.addEventListener(\u0026#39;securitypolicyviolation\u0026#39;, () =\u0026gt; { console.log(\u0026#34;Detected a redirect to somewhere other than example.org\u0026#34;); }); // Try to fetch example.org. If it redirects to anoter cross-site website // it will trigger a CSP violation event fetch(\u0026#39;https://example.org/might_redirect\u0026#39;, { mode: \u0026#39;no-cors\u0026#39;, credentials: \u0026#39;include\u0026#39; }); \u0026lt;/script\u0026gt;   Case Scenarios #  An online bank decides to redirect wealthy users to attractive stock opportunities by triggering a navigation to a reserved space on the website when these users consult their account balance. If this is only done for a specific group of users, it becomes possible for an attacker to leak the \u0026ldquo;client status\u0026rdquo; of the user.\nDefense #     Attack Alternative SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     history.length (iframes) ‚úîÔ∏è ‚ùå ‚úîÔ∏è FIP   history.length (windows) ‚ùå ‚úîÔ∏è ‚ùå NIP   onload event inside an iframe ‚úîÔ∏è ‚ùå ‚úîÔ∏è FIP   Download bar ‚úîÔ∏è ‚ùå ‚ùå   \\(^{1}\\)   NIP   Download Navigation (iframes) ‚úîÔ∏è ‚ùå ‚ùå \\(^{1}\\)   FIP   Download Navigation (windows) ‚ùå ‚ùå \\(^{1}\\)   ‚ùå NIP   Inflation ‚úîÔ∏è ‚ùå ‚ùå RIP   CSP Violations ‚úîÔ∏è ‚ùå ‚ùå RIP üîó NIP    üîó ‚Äì Defense mechanisms must be combined to be effective against different scenarios.\n  Neither COOP nor Framing Protections helps with the mitigation of the redirect leaks because when the header Content-Disposition is present, other headers are being ignored. SameSite cookies in Lax mode could protect against iframing a website, but won\u0026rsquo;t help with the leaks through window references.  Real-World Examples #  A vulnerability reported to Twitter used this technique to leak the contents of private tweets using XS-Search. This attack was possible because the page would only trigger a navigation if there were results to the user query 3.\nReferences #    Disclose domain of redirect destination taking advantage of CSP, link \u0026#x21a9;\u0026#xfe0e;\n Using Content-Security-Policy for Evil, link \u0026#x21a9;\u0026#xfe0e;\n Protected tweets exposure through the url, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:13,href:'/docs/attacks/timing-attacks/network-timing/',title:"Network Timing",section:"Timing Attacks",content:"Network Timing side-channels have been present on the web since its inception 1 2. These attacks have had different levels of impact over time, gaining new attention when browsers started shipping high-precision timers like performance.now().\nTo obtain timing measurements, attackers must use a clock, either an implicit or an explicit one. These clocks are usually interchangeable for the purposes of XS-Leaks and only vary in accuracy and availability. For simplicity, this article assumes the use of the performance.now() API, an explicit clock present in all modern browsers.\nThis side-channel allows attackers to infer information from a cross-site request based on how much time it takes to complete that request 3. The network timing measurement may vary based on the user state and it\u0026rsquo;s usually connected to the:\n Resource size. Computation time in the backend. Number and size of sub-resources. Cache status.   tip\nLearn more about the different types of clocks in the Clocks article.  Modern Web Timing Attacks #  The performance.now() API can be used to measure how much time it takes to perform a request:\n// Start the clock var start = performance.now() // Measure how long it takes to complete the fetch requests fetch(\u0026#39;https://example.org\u0026#39;, { mode: \u0026#39;no-cors\u0026#39;, credentials: \u0026#39;include\u0026#39; }).then(() =\u0026gt; { // When fetch finishes, calculate the difference  var time = performance.now() - start; console.log(\u0026#34;The request took %d ms.\u0026#34;, time); }); Onload events #  A similar process can be used to measure how long it takes to fetch a resource by simply watching for an onload event:\n// Create a script element pointing to the page we want to time var script = document.createElement(\u0026#39;script\u0026#39;); script.src = \u0026#34;https://example.org\u0026#34;; document.body.appendChild(script); // Start the clock var start = performance.now(); // When script loads, caculate the time it took to finish the request script.onload = () =\u0026gt; { var time = performance.now() - start; console.log(\u0026#34;The request took %d ms.\u0026#34;, time) }   tip\nA similar technique can be used for other HTML elements, e.g. \u0026lt;img\u0026gt;, \u0026lt;link\u0026gt;, or \u0026lt;iframe\u0026gt;, which could be used in scenarios where other techniques fail. For example, if Fetch Metadata blocks loading a resource into a script tag, it may allow loading it into an image tag.   tip\nAn alternative way could be to use image.complete property. More information here.  Cross-window Timing Attacks #  An attacker can also measure the network timing of a page by opening a new window with window.open and waiting for the window to start loading. The snippet below shows how to make this measurement:\n// Open a new window to measure when the iframe starts loading var win = window.open(\u0026#39;https://example.org\u0026#39;); // Measure the initial time var start = performance.now(); // Define the loop function measure(){ try{ // If the page has loaded, then it will be on a different origin  // so `win.origin` will throw an exception  win.origin; // If the window is still same-origin, immediately repeat the loop but  // without blocking the event loop  setTimeout(measure, 0); }catch(e){ // Once the window has loaded, calculate the time difference  var time = performance.now() - start; console.log(\u0026#39;It took %d ms to load the window\u0026#39;, time); } } // Initiate the loop that breaks when the window switches origins measure();   note\nNote that this POC uses setTimeout in order to create the rough equivalent of a while(true) loop. It is necessary to implement it in this way in order to avoid blocking the JS event loop.   tip\nThis technique can also be adapted to measure the Execution Timing of a page by making the event loop busy.  Unload events #  The unload and beforeunload events can be used to measure the time it takes to fetch a resource. This works because beforeunload is triggered when the browser requests a new navigation request, while unload is triggered when that navigation actually occurs. Because of this behaviour, it is possible to calculate the time difference between these two events and measure the time it took the browser to complete fetching the resource.\n info\nThe time difference between unload and beforeunload is not affected by the x-frame-options (XFO) header, because the event is triggered before the browser learns about the response headers.  The below snippet makes use of the SharedArrayBuffer clock which needs to be initiated before the snippet is ran:\n// Create a Shared buffer to be used by a WebWorker var sharedBuffer = new SharedArrayBuffer(Uint32Array.BYTES_PER_ELEMENT); var sharedArray = new Uint32Array(sharedBuffer); // Follow the steps of initiating the WebWorker and then call worker.postMessage(sharedBuffer); var start; iframe.contentWindow.onbeforeunload = () =\u0026gt; { // Get the \u0026#34;time\u0026#34; during the navigation  start = Atomics.load(sharedArray, 0); } iframe.contentWindow.onpagehide = () =\u0026gt; { // Get the \u0026#34;time\u0026#34; after the navigation  var end = Atomics.load(sharedArray, 0); console.log(\u0026#39;The difference between events was %d iterations\u0026#39;, end - start); };   tip\nThe SharedArrayBuffer clock was used to create a high-resolution timer. However, the time difference between the beforeunload and unload events of iframes can be measured with other clocks as well, e.g. performance.now().   tip\nThe presented snippet makes use of iframes to make the measurement. A variation of this attack can also use window references, which is harder to protect against.  Sandboxed Frame Timing Attacks #  If a page doesn\u0026rsquo;t have any Framing Protections implemented, an attacker can time how long it takes for the page and all subresources to load over the network. By default, the onload handler for an iframe is invoked after all the resources have been loaded and all JavaScript has finished executing. But, an attacker can eliminate the noise of script execution by including the sandbox attribute in the \u0026lt;iframe\u0026gt;. This attribute blocks a lot of features including JavaScript execution, which results in almost pure network measurement.\nvar iframe = document.createElement(\u0026#39;iframe\u0026#39;); // Set the URL of the destination website iframe.src = \u0026#34;https://example.org\u0026#34;; // Set sandbox attribute to block script execution iframe.sandbox = \u0026#34;\u0026#34;; document.body.appendChild(iframe); // Measure the time before the request was initiated var start = performance.now(); iframe.onload = () =\u0026gt; { // When iframe loads, calculate the time difference  var time = performance.now() - start; console.log(\u0026#34;The iframe and subresources took %d ms to load.\u0026#34;, time) } Timeless Timing Attacks #  Other types of attacks do not consider the notion of time to perform a timing attack 4. Timeless attacks consist of fitting two HTTP requests (the baseline and the attacked request) in a single packet, to guarantee they arrive to the server at the same time. The server will process the requests concurrently, and return a response based on their execution time as soon as possible. One of the two requests will arrive first, allowing the attacker to infer the time difference by comparing the order in which the requests arrived.\nThe advantage of this technique is the independence from network jitter and uncertain delays, something that is always present in the remaining techniques.\n important\nThis attack is limited to specific versions of HTTP and joint scenarios. It makes certain assumptions and has requirements regarding server behavior.  Defense #     Attack Alternative SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     Modern Timing Attacks ‚úîÔ∏è ‚ùå ‚ùå RIP üîó NIP   Frame Timing (Network) ‚úîÔ∏è ‚ùå ‚ùå FIP   Frame Timing (Sandbox) ‚úîÔ∏è ‚ùå ‚ùå FIP   Cross-window Timing ‚ùå ‚úîÔ∏è ‚ùå NIP   Timeless Timing ‚úîÔ∏è ‚úîÔ∏è ‚ùå ‚ùì    üîó ‚Äì Defense mechanisms must be combined to be effective against different scenarios.\nReferences #    Exposing Private Information by Timing Web Applications, link \u0026#x21a9;\u0026#xfe0e;\n Cross-domain search timing, link \u0026#x21a9;\u0026#xfe0e;\n The Clock is Still Ticking: Timing Attacks in the Modern Web - Section 4.3.3, link \u0026#x21a9;\u0026#xfe0e;\n Timeless Timing Attacks: Exploiting Concurrency to Leak Secrets over Remote Connections, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:14,href:'/docs/attacks/timing-attacks/performance-api/',title:"Performance API",section:"Timing Attacks",content:"Performance API #  The Performance API provides access to performance-related information enhanced by the data from the Resource Timing API which provides the timings of network requests such as the duration but when there‚Äôs a Timing-Allow-Origin: * header sent by the server the transfer size and domain lookup time is also provided.\nThis data can be accessed by using performance.getEntries or performance.getEntriesByName It can also be used to get the execution time using the difference of performance.now() however this seems to be less precise for a chrome fetch because it only provides the milliseconds.\nNetwork duration #  It is possible to retrieve the network duration of a request from the performance API.\nThe below snippet performs a network request then after 200ms it gets the duration from the performance object.\nasync function getNetworkDuration(url) { let href = new URL(url).href; // Using an image instead of fetch() as some requests had duration = 0  let image = new Image().src = href; // Wait for request to be added to performance.getEntriesByName();  await new Promise(r =\u0026gt; setTimeout(r, 200)); // Get last added timings  let res = performance.getEntriesByName(href).pop(); console.log(\u0026#34;Request duration: \u0026#34; + res.duration); return res.duration } await getNetworkDuration(\u0026#39;https://example.org\u0026#39;);   info\nUnlike other browsers, Firefox provides the measurements in milliseconds.  Detecting X-Frame-Options #  If displaying a page inside an embed (e.g. because of the X-Frame-Options header) it will not be added to the performance object in Chrome.\nasync function isFrameBlocked(url) { let href = new URL(url).href; // There may be requests for this url before the function was run.  let start_count = performance.getEntriesByName(href).length; let embed = document.createElement(\u0026#39;embed\u0026#39;); embed.setAttribute(\u0026#34;hidden\u0026#34;, true); embed.src = href; document.body.appendChild(embed); // Wait for request to be added to performance.getEntriesByName();  await new Promise(r =\u0026gt; setTimeout(r, 1000)); // Remove test embed  document.body.removeChild(embed) return performance.getEntriesByName(href).length === start_count; } await isFrameBlocked(\u0026#39;https://example.org\u0026#39;);   note\nThis technique does seem to only work in Chromium based browsers  Detecting cached resources #  With the performance API it is possible to detect whether a resource was cached or not. Unless Cross-Origin Read Blocking is triggered (resource is html) the resource will get cached in the processs of the check.\nasync function ifCached2(url) { let href = new URL(url).href; await fetch(href, {mode: \u0026#34;no-cors\u0026#34;, credentials: \u0026#34;include\u0026#34;}); // Wait for request to be added to performance.getEntriesByName();  await new Promise(r =\u0026gt; setTimeout(r, 200)); // Get last added timings  let res = performance.getEntriesByName(href).pop(); console.log(\u0026#34;Request duration: \u0026#34; + res.duration); // Check if is 304  if (res.encodedBodySize \u0026gt; 0 \u0026amp;\u0026amp; res.transferSize \u0026gt; 0 \u0026amp;\u0026amp; res.transferSize \u0026lt; res.encodedBodySize) return true if (res.transferSize \u0026gt; 0) return false; if (res.decodedBodySize \u0026gt; 0) return true; // Use duration if theirs no Timing-Allow-Origin header  return res.duration \u0026lt; 10; } Connection speed #  It is possible to measure the speed of the connection in octets.\nasync function getSpeed(count = 10) { var total = 0; // Make multiple requests for average  for (let i = 0; i \u0026lt; count; i++) { // Make request to the current origin bypassing cache  await fetch(location.href, {cache: \u0026#34;no-store\u0026#34;}); // Wait for timings to get added  await new Promise(r =\u0026gt; setTimeout(r, 200)); // Get latest timing for location  let page = window.performance.getEntriesByName(location.href).pop(); // Get response time divided by transferSize  total += (page.responseEnd - page.responseStart) / page.transferSize; } // Get average response time for requests  return total/count } await averageSpeed = getSpeed(); "}),a.add({id:15,href:'/docs/attacks/cache-probing/',title:"Cache Probing",section:"Attacks",content:"The principle of Cache Probing consists of detecting whether a resource was cached by the browser. The concept has been known since the beginning of the web 1 and initially relied on detecting timing differences.\nWhen a user visits a website, some resources such as images, scripts, and HTML content are fetched and later cached by the browser (under certain conditions). This optimization makes future navigations faster as the browser serves those resources from disk instead of requesting them again. If an attacker can detect which resources are cached, this information can be enough to leak whether a user accessed a specific page in the past.\nA variation of Cache Probing abuses Error Events to perform more accurate and impactful attacks.\nAttack Principle #  An attacker wants to know whether a user visited a certain social network:\n When the user visits the social network some of the subresources are cached. The user visits an attacker-controlled page which fetches a resource that is usually fetched by the social network. Using a Network Timing XS-Leak, the attacker page can detect the difference between a response coming from the cache (i.e. step 1 occurred) or coming from the network (i.e. step 1 did not occur): the delay is significantly lower if a request is served from the cache.  Cache Probing with Error Events #  Cache Probing with Error Events 2 allows more accurate attacks. Instead of relying on timing measurements, this approach leverages Error Events and some server-side behavior to detect whether a resource was cached. The attack requires the following steps:\n Invalidating the resource from the browser cache. This step is required to make sure the attack does not consider a resource previously cached in another visit. Performing a request that causes different items to be cached depending on the user\u0026rsquo;s state. For example, loading a page that includes a specific image only if the user is logged in. This request can be triggered by navigating to the target website with \u0026lt;link rel=prerender.., embedding the website in an iframe, or opening a new window with window.open. Triggering a request that causes the server to reject the request. For example, including an overlong referer header that makes the server reject the request. If the resource was cached in step 2, this request succeeds instead of triggering an error event.  Invalidating the cache #  To invalidate a resource from the cache, the attacker must force the server to return an error when fetching that subresource. There are a couple of ways to achieve this:\n A fetch request with a cache:'reload'option that is aborted with AbortController.abort() before new content has been received, but after the request was initiated by the browser. A request with an overlong referer header and 'cache':'reload'. This might not work as browsers capped the length of the referrer to prevent this. A POST request with a fetch no-cors. Sometimes, even in cases where an error is not returned, the browser invalidates the cache. Request headers such as Content-Type, Accept, Accept-Language, etc. that may cause the server to fail (more application dependent). Other request properties.  Often, some of these methods might be considered a bug in the browser (e.g. this bug).\nCORS error on Origin Reflection misconfiguration #  Origin reflection is a behavior in which a globally accessible resource is provided with a Access-Control-Allow-Orign (ACAO) header whose value reflects the origin that initialized the request. This can be considered as CORS misconfiguration 3 and can be used to detect whether the resource exists in the browser cache.\n info\nFor example, Flask framework promotes origin reflection as the default behavior.  If a resource hosted on server.com is requested from target.com then the origin could be reflected in the response headers as: Access-Control-Allow-Origin: target.com. If the resource is cached, this information is stored together with the resource in the browser cache. With that, if attacker.com tries to fetch the same resource there are two possible scenarios:\n The resource is not in cache: the resource could be fetched and stored together with the Access-Control-Allow-Origin: attacker.com header. The resource was already in cache: fetch attempt will try to fetch the resource from the cache but it will also generate a CORS error due to the ACAO header value mismatch with the requesting origin (target.com origin was expected but attacker.com was provided). Here below is provided an example code snippet epxloting this vulnerability to infer the cache status of the victim\u0026rsquo;s browser.  // The function simply take a url and fetch it in CORS mode // if the fetch raises an error, it will be a CORS error due to the // origin mismatch between attacker.com and victim\u0026#39;s ip function checkCachedResource(url) { fetch(url, { mode: \u0026#34;cors\u0026#34; }).catch((e) =\u0026gt; { return true }); return false } // This makes sense only if the attacker alredy knows that // server.com suffers from origin reflection CORS misconfiguration var resource_url = \u0026#34;server.com/reflected_origin_resource.html\u0026#34; verdict = checkCachedResource(resource_url) console.log(\u0026#34;Resource was cached: \u0026#34; + verdict)   tip\nThe best way to mitigate this is to avoid origin reflection and use the header Access-Control-Allow-Origin: * for globally accessible and unauthenticated resources.  Fetch with AbortController #  The below snippet shows how the AbortController interface could be combined with fetch and setTimeout to both detect whether the resource is cached and to evict a specific resource from the browser cache. A nice feature of this technique is that the probing occurs without caching new content in the process.\nasync function ifCached(url, purge = false) { var controller = new AbortController(); var signal = controller.signal; // After 9ms, abort the request (before the request was finished).  // The timeout might need to be adjusted for the attack to work properly.  // Purging content seems to take slightly less time than probing  var wait_time = (purge) ? 3 : 9; var timeout = await setTimeout(() =\u0026gt; { controller.abort(); }, wait_time); try { // credentials option is needed for Firefox  let options = { mode: \u0026#34;no-cors\u0026#34;, credentials: \u0026#34;include\u0026#34;, signal: signal }; // If the option \u0026#34;cache: reload\u0026#34; is set, the browser will purge  // the resource from the browser cache  if(purge) options.cache = \u0026#34;reload\u0026#34;; await fetch(url, options); } catch (err) { // When controller.abort() is called, the fetch will throw an Exception  if(purge) console.log(\u0026#34;The resource was purged from the cache\u0026#34;); else console.log(\u0026#34;The resource is not cached\u0026#34;); return false } // clearTimeout will only be called if this line was reached in less than  // wait_time which means that the resource must have arrived from the cache  clearTimeout(timeout); console.log(\u0026#34;The resource is cached\u0026#34;); return true; } // purge https://example.org from the cache await ifCached(\u0026#39;https://example.org\u0026#39;, true); // Put https://example.org into the cache // Skip this step to simulate a case where example.org is not cached open(\u0026#39;https://example.org\u0026#39;); // wait 1 second (until example.org loads) await new Promise(resolve =\u0026gt; setTimeout(resolve, 1000)); // Check if https://example.org is in the cache await ifCached(\u0026#39;https://example.org\u0026#39;); Defense #  Currently, there are no good defense mechanisms that would allow websites to fully protect against Cache Probing attacks. Nonetheless, a website can mitigate the attack surface by deploying Cache Protections such as:\n Cache-control headers used to prevent the resource from caching. Random Tokens used to make the URLs unpredictable for attackers. Vary: Sec-Fetch-Site used to segregate the cache by a group of origins.  A promising defense against Cache Probing attacks is partitioning the HTTP cache by the requesting origin. This browser-provided protection prevents an attacker\u0026rsquo;s origin from interfering with cached resources of other origins.\n important\nAs of November 2020, Partitioned Caches are not available in most browsers, so applications cannot rely on them.  Real World Example #  An attacker using Error Events Cache Probing was able to detect whether a user watched a specific YouTube Video by checking if the video thumbnail ended up in browser cache 4.\nReferences #    Timing Attacks on Web Privacy, link \u0026#x21a9;\u0026#xfe0e;\n HTTP Cache Cross-Site Leaks, link \u0026#x21a9;\u0026#xfe0e;\n CORS misconfiguration, link \u0026#x21a9;\u0026#xfe0e;\n Mass XS-Search using Cache Attack, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:16,href:'/docs/defenses/isolation-policies/navigation-isolation/',title:"Navigation Isolation Policy",section:"Isolation Policies",content:"Navigation Isolation Policy is a server-side protection mechanism intended to mitigate CSRF, clickjacking, reflected XSS, and XS-Leaks that make use of cross-site window contexts. This is a strict policy and has the potential to break an application since it blocks all cross-site navigations, including navigations through hyperlinks.\n tip\nInstead of rejecting all cross-site interactions, the user could be prompted to confirm the action, e.g. Confirm that you visited this page from a trusted origin, to mitigate the risk of attacks in the background, and, at the same time, help prevent unintended breakages of an application.  Implementation with Fetch Metadata #  The below snippet showcases an example implemention of the Navigation Isolation Policy with the use of Fetch Metadata headers 1:\n# Reject cross-site requests to protect from clickjacking, XS-Leaks, and other bugs def allow_request(req): # Allow any request that is not cross-site if req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-site\u0026#39;] != \u0026#39;cross-site\u0026#39;: return True # Allow requests to endpoints meant to be navigated to, e.g. homepage if req.path in whitelisted_paths: return True # Block all top-level cross-site navigations, including embeds if req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-mode\u0026#39;] in (\u0026#39;navigate\u0026#39;, \u0026#39;nested-navigate\u0026#39;): return False # Allow all other requests return True References #    Fetch Metadata Request Headers playground, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:17,href:'/docs/attacks/timing-attacks/execution-timing/',title:"Execution Timing",section:"Timing Attacks",content:"Measuring the time of JavaScript execution in a browser can give attackers information on when certain events are triggered, and how long some operations take.\nTiming the Event Loop #  JavaScript\u0026rsquo;s concurrency model is based on a single-threaded event loop which means it can only run one task at a time. If, for example, some time-consuming task blocks the event loop, the user can perceive a freeze on a page as a result of the UI thread being starved. Other tasks must wait until the blocking task finishes. Each browser implements different process models, which means some web sites might run in different threads (and event loops) depending on their relations.\nSome techniques can exploit this model to steal secrets from a cross-origin page:\n Inferring how long code from a different origin takes to run by measuring how long it takes to run next in the event pool 1 2. The attacker keeps sending events to the event loop with fixed properties, which will eventually be dispatched if the pool is empty. Other origins dispatch events to the same pool, and this is where an attacker infers the time difference by detecting if a delay occurred with one of its tasks. Stealing a secret from a cross-origin page if the said secret is being compared by an attacker-controlled string. The leak is a result of comparing time differences in the event loop of a char-by-char string comparison 2 (using the previous technique). In browsers without process isolation, cross-window communications between different origins run in the same thread, thus sharing the same event loop.   important\nThe latter attack is no longer possible in browsers with process isolation mechanisms in place. Such mechanisms are currently only present in Chromium-based browsers with Site Isolation; they are coming to Firefox soon under the name Project Fission.  Busy Event Loop #  Another technique used to measure JavaScript execution consists of blocking the event loop of a thread and timing how long it takes for the event loop to become available again. One of the main advantages of this technique is its ability to circumvent Site Isolation, as an attacker origin can influence the execution of another origin. The attack works as follows:\n Navigate the target website in a separate window with window.open or inside an iframe (if Framing Protections are not in place). Wait for the long computation to start. Load any same-site page inside an iframe, regardless of any Framing Protections.  An attacker can detect how long the target website is executed by timing how long it took for the iframe (in step 3) to trigger the onload event (Network Timing of step 3 should be minimal). Since both navigations occurred within the same context and they are same-site, they run in the same thread and share the same event loop (they can block each other).\n// Open a new window to measure how long the window blocks the event loop // for the site example.org window.open(\u0026#39;https://example.org/expensive\u0026#39;); // TODO: Wait for the expensive window to load, e.g. via timeout // then create an iframe to the same site var ifr = document.createElement(\u0026#39;iframe\u0026#39;); ifr.src = \u0026#34;https://example.org\u0026#34;; document.body.appendChild(ifr); // Measure the initial time var start = performance.now(); ifr.onload = () =\u0026gt; { // When the iframe loads calculate the time difference  var time = performance.now() - start; console.log(\u0026#39;It took %d ms to load the window\u0026#39;, time); } Service Workers #  Service Workers can be used to offer offline solutions to web applications, but they can be abused by attackers to measure the timing of JavaScript execution3. They serve as a proxy between the browser and the network and allow applications to intercept any network requests made by the main thread (document).\nTo make a timing measurement, an attacker can perform the following steps:\n The attacker registers a service worker in one of their domains (attacker.com). In the main document, the attacker issues a navigation (window.open) to the target website and instructs the Service Worker to start a timer. When the new window starts loading, the attacker navigates the reference obtained in step 2 to a page handled by the Service Worker. When the request performed in step 3 arrives at the service worker, it returns a 204 (No Content) response, which aborts the navigation. At this point, the Service Worker collects a measurement from the timer started in step 2. This measurement is affected by how long JavaScript blocked the navigation.  Since no navigation actually occurs, steps 3 to 5 can be repeated to obtain more measurements on successive JavaScript execution timings.\nCSS Injections #   warning\nThis group of XS-Leaks requires a CSS injection on the target page.  Among the different CSS injection vectors, the most noticeable one is the abuse of CSS Selectors. They can be used as an expression to match and select certain HTML elements. For example, the selector input[value^=\u0026quot;a\u0026quot;] is matched if the value of an input tag starts with the character \u0026ldquo;a\u0026rdquo;. So, to detect if a CSS Selector matches the expression, attackers can trigger a callback to one of their websites using certain properties like background, @import, etc. 4 5. The matching process can easily be brute-forced, and extended to the full string.\njQuery, CSS Selectors \u0026amp; Short-circuit Timing #  Attackers can abuse another interesting behavior of CSS selectors which is short-circuit evaluation of expressions. This expression is received in a URL hash and evaluated if the page executes jQuery(location.hash) 6.\nA timing attack is possible because the expression is compared from right to left, so if the selector main[id='site-main'] does not match and fails to evaluate, the other parts of the selector (*:has(*:has(*:has(*))))), which take longer to execute, are ignored (just like the and operator, but backwards).\n$(\u0026#34;*:has(*:has(*:has(*)) *:has(*:has(*:has(*))) *:has(*:has(*:has(*)))) main[id=\u0026#39;site-main\u0026#39;]\u0026#34;)   tip\nIn browsers with process isolation mechanisms, Service Workers can be abused to obtain the execution timing measurement or tricks like Busy Event Loop tricks can be used to circumvent Site Isolation.  ReDoS #   warning\nThis group of XS-Leaks requires an injection of Regex Expressions on the target page.  Regular Expression Denial of Service (ReDoS) is a technique which results in a Denial of Service in applications that allow regex as user input 2 7. Maliciously crafted regular expressions can be made to run in exponential time. This can be used as an XS-Leak vector if a regex can be injected that has a different runtime depending on the data on the page. This could happen on the client-side or the server-side.\nDefense #     Attack Alternative SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     T. Event Loop ‚ùå ‚ùì ‚ùå NIP   Service Workers ‚úîÔ∏è ‚úîÔ∏è ‚ùå NIP   jQuery ‚úîÔ∏è ‚ùå ‚ùå NIP   ReDoS ‚úîÔ∏è ‚ùå ‚ùå NIP   Busy Event Loop ‚úîÔ∏è ‚úîÔ∏è ‚ùå NIP    References #    Loophole: Timing Attacks on Shared Event Loops in Chrome, link \u0026#x21a9;\u0026#xfe0e;\n Matryoshka - Web Application Timing Attacks (or.. Timing Attacks against JavaScript Applications in Browsers), link \u0026#x21a9;\u0026#xfe0e;\n Security: XS-Search + XSS Auditor = Not Cool, link \u0026#x21a9;\u0026#xfe0e;\n CSS Injection Primitives, link \u0026#x21a9;\u0026#xfe0e;\n HTTPLeaks, link \u0026#x21a9;\u0026#xfe0e;\n A timing attack with CSS selectors and Javascript, link \u0026#x21a9;\u0026#xfe0e;\n A Rough Idea of Blind Regular Expression Injection Attack, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:18,href:'/docs/attacks/timing-attacks/hybrid-timing/',title:"Hybrid Timing",section:"Timing Attacks",content:"Hybrid Timing Attacks allow attackers to measure the sum of a group of factors that influence the final timing measurement. These factors include:\n Network delays Document parsing Retrieval and processing of subresources Code execution  Some of the factors differ in value depending on the application. This means that Network Timing might be more significant for pages with more backend processing, while Execution Timing can be more significant in applications processing and displaying data within the browser. Attackers can also eliminate some of these factors to obtain more precise measurements. For example, an attacker could preload all of the subresources by embedding the page as an iframe (forcing the browser to cache the subresources) and then perform a second measurement, which excludes any delay introduced by the retrieval of those subresources.\nFrame Timing Attacks (Hybrid) #  If a page does not set Framing Protections, an attacker can obtain a hybrid measurement that considers all of the factors. This attack is similar to a Network-based Attack, but when the resource is retrieved, the page is rendered and executed by the browser (subresources fetched and JavaScript executed). In this scenario, the onload event only triggers once the page fully loads (including subresources and script execution).\nvar iframe = document.createElement(\u0026#39;iframe\u0026#39;); // Set the URL of the destination website iframe.src = \u0026#34;https://example.org\u0026#34;; document.body.appendChild(iframe); // Measure the time before the request was initiated var start = performance.now(); iframe.onload = () =\u0026gt; { // When iframe loads, calculate the time difference  var time = performance.now() - start; console.log(\u0026#34;The iframe and subresources took %d ms to load.\u0026#34;, time) } Defense #     Attack Alternative SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     Frame Timing (Hybrid) ‚úîÔ∏è ‚ùå ‚úîÔ∏è FIP    "}),a.add({id:19,href:'/docs/attacks/id-attribute/',title:"ID Attribute",section:"Attacks",content:"The id attribute is widely used to identify HTML elements. Unfortunately, cross-origin websites can determine whether a given id is set anywhere on a page by leveraging the focus event and URL fragments. If https://example.com/foo#bar is loaded, the browser attempts to scroll to the element with id=\u0026quot;bar\u0026quot;. This can be detected cross-origin by loading https://example.com/foo#bar in an iframe; if there is an element with id=\u0026quot;bar\u0026quot;, the focus event fires. The blur event can also be used for the same purpose 1.\nSome web applications set id attributes in focusable elements that can lead to disclosing user information. These ids can either contain information directly related to the user (e.g. a secret), or information associated with a user state (e.g. account status).\nCode snippet #  The below snippet presents an example of detecting the ID attribute from another site:\n// Listen to onblur event onblur = () =\u0026gt; { alert(\u0026#39;Focus was lost, so there is a focusable element with the specified ID\u0026#39;); } var ifr = document.createElement(\u0026#39;iframe\u0026#39;); // If a page has a focusable element with id=\u0026#34;x\u0026#34; it will gain focus // E.g. \u0026lt;input id=\u0026#34;x\u0026#34; value=\u0026#34;test\u0026#34; /\u0026gt; ifr.src = \u0026#39;https://example.org/#x\u0026#39;; document.body.appendChild(ifr);   info\nThe above technique doesn\u0026rsquo;t seem to work in Firefox.  Case Scenarios #  Some examples of id-attribute-based attacks are:\n A bank allows its clients to generate short numeric One-Time PINs (OTP) in the browser application to authenticate sessions on mobile devices. The bank used the OTP as the id of a button that is used to show the PIN to the client. This approach could be abused to steal these OTP codes by brute-forcing every option and then using them to compromise user accounts. A web application uses a specific set of predefined ids and HTML elements when an account has a premium status or the user is of a certain gender. The attacker can detect whether a specific id is present on the victim\u0026rsquo;s page and leak the account information.  Defense #     SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     ‚úîÔ∏è ‚úîÔ∏è ‚ùå FIP    References #    Leaking IDs using focus, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:20,href:'/docs/attacks/postmessage-broadcasts/',title:"postMessage Broadcasts",section:"Attacks",content:"Applications often use postMessage broadcasts to share information with other origins. Using postMessage can lead to two kinds of XS-Leaks:\n  Sharing sensitive messages with untrusted origins\n The postMessage API supports a targetOrigin parameter that can be used to restrict which origins can receive the message. If the message contains any sensitive data, it is important to use this parameter.    Leaking information based on varying content or on the presence of a broadcast\n Similar to other XS-Leak techniques, this could be used to form an oracle. For example, if an application sends a postMessage broadcast saying \u0026ldquo;Page Loaded\u0026rdquo; only if a user with a given username exists, this could be used to leak information.    Defense #  There is no clear solution to mitigate this XS-Leak as it depends deeply on the purpose of sending a postMessage broadcast. Applications should limit postMessage communications to a group of known origins. When this is not possible, the communications should behave consistently regardless of the state to prevent attackers from inferring information based on differences between the communications.\nReferences #  "}),a.add({id:21,href:'/docs/defenses/isolation-policies/',title:"Isolation Policies",section:"Defense Mechanisms",content:"Isolation Policies #  This section describes proposed defenses against different kinds of cross-site interactions, presented in the form of isolation policies:\n To defend against cross-site requests for common resources (e.g. scripts, images, fetch) with Fetch Metadata, check Resource Isolation Policy. To defend against cross-site framing with Fetch Metadata, check Framing Isolation Policy. To defend against cross-site navigational requests with Fetch Metadata, check Navigation Isolation Policy. To defend against all cross-site interactions with either Fetch Metadata, SameSite cookies, or the Referer header, check Strict Isolation Policy.  "}),a.add({id:22,href:'/docs/defenses/isolation-policies/strict-isolation/',title:"Strict Isolation Policy",section:"Isolation Policies",content:"Strict Isolation Policy is intended to protect against all cross-site interactions (including navigations to the application through hyperlinks). This is a very strict policy that has the potential to prevent applications from functioning properly.\n tip\nInstead of rejecting all cross-site interactions, the user could be prompted to confirm the action, e.g. Confirm that you visited this page from a trusted origin, to mitigate the risk of attacks in the background, and, at the same time, help prevent unintended breakages of an application.\nHowever, this would only work for navigational requests, since other resources are loaded in the background.\n Implementation with Fetch Metadata #  The below snippet showcases an example implementation of Strict Isolation Policy by an application:\n# Reject cross-origin requests to protect from CSRF, XSSI, and other bugs def allow_request(req): # Allow requests from browsers which don\u0026#39;t send Fetch Metadata if not req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-site\u0026#39;]: return True # Block any cross-site request if req[\u0026#39;headers\u0026#39;][\u0026#39;sec-fetch-site\u0026#39;] == \u0026#39;cross-site\u0026#39;: return False # Allow all other requests return True Implementation with SameSite cookies #  If a server sends a cookie with the SameSite=strict flag, any returned request that doesn\u0026rsquo;t contain that cookie can be rejected, as showcased in this snippet:\n# Reject cross-origin requests to protect from CSRF, XSSI, and other bugs def allow_request(req): if req[\u0026#39;cookies\u0026#39;][\u0026#39;strict-cookie\u0026#39;] == \u0026#39;true\u0026#39;: return True # Block requests without a strict cookie return False Implementation with Referer #  It is also possible to reject requests from untrusted origins with the Referer header:\n# Reject requests that came from untrusted referrers def allow_request(req): # check if the referer header is trusted, i.e. exists in trusted_referers dict if req[\u0026#39;headers\u0026#39;][\u0026#39;referer\u0026#39;] in trusted_referers: return True # Block requests without a strict cookie return False   important\nIt is not guaranteed that every request will contain the Referer header (e.g. extensions can strip the header) which could potentially break an application. Also be aware that it is possible to set the value of Referer to null.\nTwitter deployed 1 a similar protection against XS-Leaks.\n  Protecting user identity against Silhouette, link \u0026#x21a9;\u0026#xfe0e;\n    "}),a.add({id:25,href:'/docs/attacks/experiments/',title:"Experiments",section:"Attacks",content:"Experiments #  This section presents XS-Leaks that affect experimental features. Experimental features are usually hidden under a browser preference flag and their exact specification is under active discussion. It\u0026rsquo;s important to be aware of these features and follow their development from the early stages of implementation to prevent XS-Leaks from happening.\n"}),a.add({id:26,href:'/docs/defenses/secure-defaults/',title:"Secure Defaults",section:"Defense Mechanisms",content:"Secure Defaults #  This section contains articles discussing two types of secure defaults:\n Partitioned Caches ‚Äì Ensure that cache resources cannot be shared in between different sites. Cross Origin Read Blocking (CORB) ‚Äì Prevents certain types of responses from being referenced by certain classes of requests.  "}),a.add({id:27,href:'/docs/attacks/historical/',title:"Historical",section:"Attacks",content:"Historical Attacks #  The articles in this section present XS-Leaks that have been addressed within browsers and no longer work. Different mitigation strategies were applied, such as:\n Reducing the accuracy of some powerful APIs. Adding noise to a certain measurement to prevent any malicious inference from it. Deprecating and removing features and APIs. Changing the feature\u0026rsquo;s behavior.  "}),a.add({id:28,href:'/docs/defenses/',title:"Defense Mechanisms",section:"Docs",content:"Defense Mechanisms #  Defending against all possible XS-Leaks Attack Vectors is not a trivial task. Each one of the attack vectors affects different web and browser components and has its quirks. Some bug bounty programs, such as Google VRP, even stopped paying for new XS-Leaks reports as they are focusing on large systemic changes to defend against XS-Leaks 1. Google and many other companies believe that the right approach to fixing XS-Leaks is to invest time and engineering power into new large scale mitigations and changes to the web platform that applications can use to mitigate entire categories of XS-Leaks.\nBrowsers now provide a number of useful opt-in mechanisms that can be used to mitigate XS-Leaks. While these provide strong protections, the disadvantage is that they are not yet well supported by every browser. Defending against XS-Leaks effectively requires a mixture of different techniques, each of which is described in detail below.\nOpt-in Mechanisms #  These defense mechanisms allow applications to address classes of similar XS-Leaks at the same time. These protections can either allow applications to change the behavior of the browser or provide additional information that applications can use to change their own behavior.\n tip\nDeploying a combination of opt-in defense mechanisms should be the default strategy. Not only do they protect against XS-Leaks, but also against other vulnerabilities such as XSSI, Clickjacking, CSRF, etc.   important\nWhen using any mitigations that rely on browser support, be sure to check that they are well supported by your customers' browsers. For example, fetch metadata headers are a great tool, but are currently only supported in Chromium-based browsers. Check MDN for up-to-date information on browser support for different standards.  Application Design #  Application design techniques are focused on carefully designing the application in a way that prevents XS-Leaks. This is a very useful approach when it is not practical to enable stronger global protections immediately. The other big advantage is that careful application design can stop XS-Leaks even on older browsers that don\u0026rsquo;t support the newest browser standards.\n note\nIt is very difficult to use application design techniques to block every XS-Leak technique across an entire application. While application design techniques are effective at stopping severe leaks, opt-in mechanisms provided by the browser are a better overall solution.  Secure Defaults #  Browser vendors are actively working on changing default behaviors to help mitigate some of the XS-Leaks mentioned in this wiki. Changing default behaviors is a balancing act between improving security and preserving backwards compatibility.\n important\nSecure defaults are amazing! They can help protect applications and users without any additional effort from developers. But note that they\u0026rsquo;re unlikely to completely prevent XS-Leaks.  References #    Google Bughunter University - XSLeaks and XS-Search, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:29,href:'/docs/contributions/',title:"Contributions",section:"Docs",content:"Contributions #  This page explains how you can contribute to the XS-Leaks wiki and acknowledges the users who have contributed content.\nContribution guidelines #  The article source files reside in the /content directory in the wiki repository.\nYou can make changes to articles in various ways:\nPull requests #  In order to submit a pull request:\n Fork the repository. Make changes there and place them into a pull request. Submit the pull request of the branch to master in the main folder.  If you are not sure about the folder structure, you can look up how other articles were written.\nDirect edits #  Under every article, there is an Edit this article anchor which redirects you straight to the GitHub editor.\nGithub issues #  If neither of the above options work for you, we\u0026rsquo;d appreciate if you created a new issue in the main wiki repository where you can explain the improvement, issue, or any other comment you have regarding the current version of the wiki.\nLocal deployment #  The wiki is built using the Hugo framework.\nYou can run a local environment by following these steps:\n Install the Hugo Framework, extended version \u0026gt; 0.68. Clone this repo. Run hugo server --minify in the root directory. Open your browser and go to http://localhost:1313 (or as indicated by the Hugo output).  Wiki theme #  We use the Hugo Book Theme with custom modifications.\nCustom hint shortcode #  We modified the default Hints used by the theme; the modified boxes are listed below:\n info\nThis is an Info box for the {{\u0026lt; hint info \u0026gt;}} shortcode.   note\nThis is a Note box for the {{\u0026lt; hint note \u0026gt;}} shortcode.   example\nThis is an Example box for the {{\u0026lt; hint example \u0026gt;}} shortcode.   tip\nThis is a Tip box for the {{\u0026lt; hint tip \u0026gt;}} shortcode.   important\nThis is an Important box for the {{\u0026lt; hint important \u0026gt;}} shortcode.   warning\nThis is a Warning box for the {{\u0026lt; hint warning \u0026gt;}} shortcode.  Original style #  The original hint style can be used by adding a third parameter, noTitle, to the shortcode, e.g.:\n{{\u0026lt; hint example noTitle \u0026gt;}}  Acknowledgements #  We would like to thank the following users who contributed to this XS-Leaks wiki:\nManuel Sousa, terjanq, Roberto Clapis, David Dworken, NDevTK, 1lastBr3ath, Brasco, rick.titor\nIn addition, we would also like to acknowledge the users who contributed to the predecessor of the current XS-Leaks wiki:\nEduardo' Vela\u0026quot; \u0026lt;Nava\u0026gt; (sirdarckcat), Ron Masas, Luan Herrera, Sigurd, larson reever, Frederik Braun Masato Kinugawa, sroettger\nAnd finally, our thanks go to all other amazing researchers that participate in sharing and exploring the depths of XS-Leaks!\n"}),a.add({id:31,href:'/docs/defenses/opt-in/fetch-metadata/',title:"Fetch Metadata",section:"Opt-In Mechanisms",content:"Fetch Metadata Request Headers are sent by browsers with HTTPS requests. These headers provide context on how a request was initiated so that applications are able to make more informed decisions on how to respond to them. This allows servers to behave differently when they detect potential attacks (e.g. unexpected cross-origin requests)[^1]. This can be very effective against cross-origin attacks like XSSI, XS-Leaks, Clickjacking, and CSRF if a strict policy is deployed on the server.\nIn the XS-Leaks scenario, servers have the ability to know when a request was made cross-origin (e.g. attacker origin) and can return a different response with no user data. This kind of response is not useful to the attacker since it does not carry any information or state about the user. Fetch Metadata can also be used to block framing or even navigational requests.\n important\nFor security reasons, Fetch Metadata headers are only attached to encrypted (HTTPS) requests.  Fetch Metadata vs. SameSite cookies #  Fetch Metadata headers can be used to extend the protections provided by SameSite cookies. While both Fetch Metadata headers and SameSite cookies can be used to reject cross-site requests, Fetch Metadata can make more informed decisions based on factors like:\n Was the request same-origin or same-site? How was the request initiated? (e.g. fetch, script, top navigation) Was the request initiated by user interaction? Was the request initiated by the browser (e.g. by entering the URL directly in the omnibox)?  This allows for a more precise deployment of protections in scenarios where SameSite cookies could break a service\u0026rsquo;s functionalities. One disadvantage of Fetch Metadata compared to SameSite cookies is that the latter can also protect unencrypted requests (HTTP) while the former can\u0026rsquo;t.\nConsiderations #  Fetch Metadata headers are a useful tool for a defense-in-depth strategy, but should not be seen as a replacement for mechanisms such as SameSite Cookies, COOP, or Framing Protections. Even though Fetch Metadata headers can be used to achieve similar results, it is a best practice to enforce these restrictions on the client side in addition to the server.\nThe usefulness of Fetch Metadata headers is dependent on the application coverage and correctness of the deployment.\nPolicies #  See Resource Isolation Policy and Framing Isolation Policy for specific policies utilizing Fetch Metadata Request Headers.\n"}),a.add({id:32,href:'/docs/defenses/design-protections/cache-protections/',title:"Cache Protections",section:"Application Design",content:"There are a number of different approaches applications can use to defend against cache probing-based XS-Leaks. These approaches are explained in the following sections.\nCache Protection via Cache-Control Headers #  If it is acceptable to disable caching, doing so provides a strong defense against cache probing attacks. Disabling caching means that every time someone loads a resource, the resource has to be fetched again. To disable caching, set a Cache-Control: no-store header on every single response that you wish to protect.\nAdvantages:\n Supported by all major browsers  Disadvantages:\n Negatively impacts site performance  Cache Protection via Random Tokens #  Rather than disabling caching, applications can include additional data in URLs in order to defend against cache probing attacks. This can be achieved by including a random token in the URL of every subresource that you reference. If an attacker cannot guess this random token, then the attacker cannot determine whether items are in the cache via any straightforward techniques.\n example\nSuppose that every page on your application loads the user\u0026rsquo;s profile photo: /user/\u0026lt;USERNAME\u0026gt;.png. An attacker could check which user is signed in by probing the cache for /user/john.png, /user/jane.png, and so on.\nThis is where a random token can come into play. If implemented, the application takes the user\u0026rsquo;s profile photo from /user/\u0026lt;USERNAME\u0026gt;.png?cache_buster=\u0026lt;RANDOM_TOKEN\u0026gt; on every load. The server does not need to do anything with this random token. It is there purely to ensure that there is no way for an attacker to probe the cache without knowing the random token.\n If implemented carefully, an application could even have a user-specific random token that is reused across page loads. This would allow subresources to still be cached since the URL would remain constant for a given user.\nAdvantages:\n Supported by every major browser Does not break caching  Disadvantages:\n Difficult to implement  Cache Protection via Fetch Metadata #  Fetch-Metadata is meant to allow servers to determine how and why a request was initiated on the client side. One piece of information that is exposed is the Sec-Fetch-Site header which specifies whether a request is coming from the same origin or a different origin. This can be combined with the Vary header in order to force the browser to segment the cache based on whether a request is made from the same origin or a different origin.\nThis is done by setting Vary: Sec-Fetch-Site on all resources you wish to protect.\n example\nAssume we have the resource cdn.example.com/image.png that we wish to protect from cache probing attacks. If we set Vary: Sec-Fetch-Site on it, this leads to the following behavior:\n If example.com tries to load the resource, the request is initiated by the same site so it is cached under (SFS: same-site, resource_url) If cdn.example.com tries to load the resource, the request is initiated by the same origin so it is cached under (SFS: same-origin, resource_url) If evil.com tries to load the resource, the request is initiated by a different site so it is cached under (SFS: cross-site, resource_url)  Note that this means cross-site requests are separated from same-site and same-origin requests.\n Advantages:\n Does not break caching  Disadvantages:\n Fetch metadata is a new standard that is currently only supported in Chromium-based browsers (e.g. Chrome and Edge) Cross-site subresources loaded on the page are not protected (e.g. subresources from CDNs) If third parties load the resource, they are not protected  "}),a.add({id:33,href:'/docs/attacks/timing-attacks/connection-pool/',title:"Connection Pool",section:"Timing Attacks",content:"Another way to measure the network timing of a request consists of abusing the socket pool of a browser 1. Browsers use sockets to communicate with servers. As the operating system and the hardware it runs on have limited resources, browsers have to impose a limit.\nTo exploit the existence of this limit, attackers can:\n Check what the limit of the browser is, for example 256 global sockets. Block   \\(255\\)  sockets for a long period of time by performing  \\(255\\)  requests to different hosts that simply hang the connection Use the  \\(256^{th}\\)  socket by performing a request to the target page. Perform a  \\(257^{th}\\)  request to another host. Since all the sockets are being used (in steps 2 and 3), this request must wait until the pool receives an available socket. This waiting period provides the attacker with the network timing of the  \\(256^{th}\\)  socket, which belongs to the target page. This works because the  \\(255\\)  sockets in step 2 are still blocked, so if the pool received an available socket, it was caused by the release of the socket in step 3. The time to release the  \\(256^{th}\\)  socket is directly connected with the time taken to complete the request.  Defense #     SameSite Cookies (Lax) COOP Framing Protections Isolation Policies     ‚ùå ‚ùå ‚ùå ‚ùå     info\nSimilar to partitioned caches, some browsers are considering to extend the principle of \u0026ldquo;split per site/origin\u0026rdquo; of resources to socket pools.  References #    Leak cross-window request timing by exhausting connection pool, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:34,href:'/docs/attacks/historical/content-type/',title:"Content-Type",section:"Historical",content:"Leaking the Content-Type of a request would provide attackers with a new way of distinguishing two requests from each other.\ntypeMustMatch #  typeMustMatch is a Boolean that reflects the typeMustMatch attribute of the object element. It ensures that a certain MIME type must be enforced when loading an object, by verifying if the Content-Type of the resource is the same as the one provided in the object. Unfortunately, this enforcement also allowed attackers to leak the Content-Type and Status Codes returned by a website 1.\nRoot Cause #  Considering the snippet below, not_loaded would be rendered if the returned Content-Type of https://target/api did not match the one in type, or if the server returned a status different than 200.\n\u0026lt;object type=\u0026#34;application/json\u0026#34; data=\u0026#34;https://example.org\u0026#34; typemustmatch\u0026gt; not_loaded \u0026lt;/object\u0026gt; Issues #  An attacker could leak the Content-Type and Status Codes of a website by detecting whether the object rendered, which happens when all conditions are met. The attacker could check the values of clientHeight and clientWidth which are likely to be different than 0 when the object renders (and returns status 200). Since typeMustMatch requires the server to return status 200 to load a resource, it would be possible to detect error pages, similar to Error Events XS-Leaks.\nThe example below shows how this behavior could be detected by embedding an object inside an iframe and checking the values of clientHeight and clientWidth when the iframe triggers the onload event.\n// Set the destination URL var url = \u0026#39;https://example.org\u0026#39;; // The content type we want to check for var mime = \u0026#39;application/json\u0026#39;; var ifr = document.createElement(\u0026#39;iframe\u0026#39;); // Load an object inside iframe since object does not trigger onload event ifr.srcdoc = ` \u0026lt;object id=\u0026#34;obj\u0026#34; type=\u0026#34;${mime}\u0026#34; data=\u0026#34;${url}\u0026#34; typemustmatch\u0026gt; error \u0026lt;/object\u0026gt;`; document.body.appendChild(ifr); // When the iframe loads, read the height of the object. If it is the height // of a single line of text, then the content type of the resource was not // `application/json`. If it is a different height, then it was `application/json`. ifr.onload = () =\u0026gt; { console.log(ifr.contentWindow.obj.clientHeight) }; Fix #  Firefox was the only browser that supported the typeMustMatch attribute 2, and since no other browsers offered support, it was removed in version 68 and from the HTML Living Standard.\nReferences #    Cross-Site Content and Status Types Leakage, link \u0026#x21a9;\u0026#xfe0e;\n Remove support for typemustmatch, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:35,href:'/docs/defenses/secure-defaults/corb/',title:"Cross-Origin Read Blocking",section:"Secure Defaults",content:"Cross-Origin Read Blocking (CORB) is a security mechanism that prevents attackers from loading certain cross-origin resources 1. This protection was created to defend against speculative side-channel attacks such as Spectre that allow attackers to read the memory of the process that both cross-site pages (e.g. attacker.com and sensitive.com) were embedded into. CORB aims to prevent attackers from loading certain sensitive cross-origin resources into an attacker-controlled process. For example, if an attacker tries to load cross-origin HTML, XML, or JSON into an img tag, CORB prevents this from happening. With CORB, the scenario is treated as though the server returned no data.\nTo classify resources, CORB uses the Content-Type header, the nosniff header, and a variety of other heuristics.\n info\nCross-Origin Resource Policy (CORP) is an opt-in protection which enforces and extends CORB.  When using CORB, be aware of the following facts:\n Currently, only Chromium-based browsers support CORB. CORB does not protect against navigational requests. This means that in browsers that do not support out-of-process iframes, a CORB-protected resource may still end up in another origin\u0026rsquo;s process if framing protections are not used. CORB introduces a new XS-Leak technique since attackers may be able to observe the results of CORB. This can lead to a variety of information leaks. However, in most cases, these information leaks have a lower impact than the data that could be leaked via speculative execution attacks.  References #    Cross-Origin Read Blocking for Web Developers, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:36,href:'/docs/defenses/opt-in/coop/',title:"Cross-Origin-Opener-Policy",section:"Opt-In Mechanisms",content:"Getting access to a website\u0026rsquo;s window object is a common prerequisite for different XS-Leak techniques. Framing Protections can ensure that an attacker cannot use iframes to access the window object, but this does not stop an attacker from accessing the window object from an opened window through window.open(url) or window.opener references.\nExploiting XS-Leaks with window.open is generally seen as the least appealing option for an attacker because the user can see it happen in the open browser window. However, it\u0026rsquo;s usually the right technique when:\n A page sets Framing Protections. A page sets Same-Site Cookies with Lax Mode (in contrast to the Strict mode, navigating a top-level window is allowed by the Lax mode).  To prevent other websites from gaining arbitrary window references to a page, applications can deploy Cross-Origin-Opener-Policy (COOP) 1 2.\nThere are three possible values for the COOP header:\n unsafe-none ‚Äì This is the default value and is how websites behave if no value is set. same-origin ‚Äì This is the strictest value. If you set same-origin, then cross-origin websites cannot get access to your window object through opening new windows. If your application relies on using window.open to open another website and communicate with it, this will be blocked by same-origin. If this is an issue, set same-origin-allow-popups instead. same-origin-allow-popups ‚Äì This value allows your website to use window.open, but does not allow other websites to use window.open against your application.  If possible, it is recommended to set same-origin. If you set same-origin-allow-popups, be sure to review what websites you open with window.open and ensure that they are trusted.\nConsiderations #  Since COOP is an opt-in mechanism and a very recent one, it can easily be overlooked by developers and security engineers. Nonetheless, it‚Äôs important to highlight the importance of this defense mechanism as it is the only way to prevent attackers from exploiting XS-Leaks which make use of window references returned by APIs like window.open (unless SameSite Cookies in the Strict mode can be widely deployed).\nDeployment #  Check out this web.dev article to learn more about the advantages of this protection and how to deploy it.\nReferences #    Cross-Origin-Opener-Policy response header (also known as COOP), link \u0026#x21a9;\u0026#xfe0e;\n Cross-Origin-Opener-Policy, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:37,href:'/docs/defenses/opt-in/corp/',title:"Cross-Origin-Resource-Policy",section:"Opt-In Mechanisms",content:"Cross-Origin Resource Policy (CORP) is a web platform security feature that allows websites to prevent certain resources from being loaded by other origins. This protection complements CORB since it is an opt-in defense, whereas CORB blocks some cross-origin reads by default. CORP is designed to protect against both speculative execution attacks and XS-Leaks by allowing developers to ensure that sensitive resources cannot end up in attacker-controlled processes. Unlike CORB, this protection is enforced in the browser only if an application opts in to the protection. Applications can define which groups of origins (\u0026lsquo;same-site\u0026rsquo;, \u0026lsquo;same-origin\u0026rsquo;, \u0026lsquo;cross-site\u0026rsquo;) are allowed to read their resources.\nIf an application sets a certain resource CORP header as \u0026lsquo;same-site\u0026rsquo; or \u0026lsquo;same-origin\u0026rsquo;, an attacker is incapable of reading that resource. This is a very strong and highly encouraged protection.\nWhen using CORP, be aware of the following facts:\n CORP does not protect against navigational requests. This means that in browsers that do not support out-of-process iframes, a CORP-protected resource may still end up in another origin\u0026rsquo;s process if framing protections are not used. The use of CORP introduces a new XS-Leak, which allows attackers to detect whether CORP was enforced in a certain request.  References #  "}),a.add({id:38,href:'/docs/defenses/opt-in/xfo/',title:"Framing Protections",section:"Opt-In Mechanisms",content:"A considerable number of XS-Leaks rely on some of the properties of iframes. If an attacker is unable to embed the contents of a page as an iframe, frame, embed or object, then the attack may no longer be possible. To mitigate XS-Leaks which rely on these objects, pages can forbid or select which origins can embed them. Doing so is possible by using the X-Frame-Options header or the CSP frame-ancestors directive.\nSince a website enforcing Framing Protections can\u0026rsquo;t be embedded from an attacker origin, the website is not rendered and the JavaScript does not run. Therefore, none of its subresources (images, JS, or CSS) are retrieved by the browser.\n tip\nThe CSP frame-ancestors directive is the more modern way of enabling framing protections. However, it is not supported by Internet Explorer, so in many cases it is recommended to use it in conjunction with the X-Frame-Options header.  Considerations #  This protection is very effective against XS-Leaks that rely on framing and can be easily implemented without breaking the vast majority of applications. This mechanism not only protects against some XS-Leaks, but also prevents attacks like clickjacking.\nDeployment #  Deploying framing protections is usually straightforward as many applications are not meant to be embedded cross-origin in an iframe. Check out this web.dev article to learn more about the advantages of this header.\n"}),a.add({id:39,href:'/docs/defenses/secure-defaults/partitioned-cache/',title:"Partitioned HTTP Cache",section:"Secure Defaults",content:"In order to defend against cache probing attacks, browser developers are actively working on implementing a partitioned HTTP cache functionality that would in essence ensure each website has a distinct cache. Since cache probing relies on the fact that a browser\u0026rsquo;s HTTP cache is shared across every website, a partitioned HTTP cache can defend against many cache probing techniques. This is done by using tuples (either (top-frame-site, resource-url) or (top-frame-site, framing-site, resource-url)) as the cache keys to ensure the cache is partitioned by the requesting site. This makes it more challenging for attackers to interact with the cached contents of different sites 1 2 3. Safari currently ships a partitioned cache 4, while Chrome and Firefox are both actively working on implementing this feature 5 6.\n tip\nFor browsers that don\u0026rsquo;t use partitioned caches, there are other defenses that applications can deploy to defend against cache probing techniques. Pages can also be designed to require some level of user interaction in order to defend against cache probing attacks.  Other Relevant Projects #  WebKit Tracking Prevention Technologies #  Safari implements a partitioned HTTP cache using (top-frame-site, resource URL) as the cache key. This is part of WebKit\u0026rsquo;s larger Tracking Prevention project.\nFirefox First Party Isolation #  First Party Isolation is a browser extension for Firefox which restricts access to cookies and persistent data (e.g. cache) per domain. This requires an opt-in on the part of the user.\nConsiderations #  Partitioned HTTP caches are a promising security feature that will eventually land in all browsers. These partitioning strategies will mitigate most of the XS-Leak techniques that leverage browser caches. In the future, partitioned caches might be extended to other browser resources, which could help mitigate other XS-Leak techniques like the Socket Exhaustion XS-Leak.\nReferences #    Double-keyed HTTP cache, link \u0026#x21a9;\u0026#xfe0e;\n Explainer - Partition the HTTP Cache, link \u0026#x21a9;\u0026#xfe0e;\n Client-Side Storage Partitioning, link \u0026#x21a9;\u0026#xfe0e;\n Optionally partition cache to prevent using cache for tracking (Webkit), link \u0026#x21a9;\u0026#xfe0e;\n Split Disk Cache Meta Bug (Blink), link \u0026#x21a9;\u0026#xfe0e;\n Top-level site partitioning (Gecko), link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:40,href:'/docs/attacks/experiments/portals/',title:"Portals",section:"Experiments",content:"Portals are a new feature of the web which is similar to iframes, but with more emphasis on speed and user experience. The portal element is only available on Chromium-based browsers under a preference flag. The corresponding specification is still under active discussion.\nUnfortunately, research of this new feature has discovered some critical issues, including new XS-Leaks 1.\nID Leaks #  Portals can be abused as an alternative to the ID Attribute XS-Leak. If a website sets framing protections, the same technique can be applied using the portal element instead 2.\nReferences #    Security analysis of \u0026lt;portal\u0026gt; element, link \u0026#x21a9;\u0026#xfe0e;\n Detecting IDs using Portal, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:41,href:'/docs/defenses/opt-in/same-site-cookies/',title:"SameSite Cookies",section:"Opt-In Mechanisms",content:"SameSite cookies are one of the most impactful modern security mechanisms for fixing security issues that involve cross-site requests. This mechanism allows applications to force browsers to only include cookies in requests that are issued same-site 1. This type of cookie has three modes: None, Lax, and Strict.\nSameSite Cookie Modes #  The following SameSite cookie modes are available:\n  None ‚Äì Disables all protections and restores the old behavior of cookies. This mode is not recommended.\n important\nThe None attribute must be accompanied by the Secure flag 1.\n  SameSite cookies explained, link \u0026#x21a9;\u0026#xfe0e;\n      Strict ‚Äì Causes the browser to not include cookies in any cross-site requests. This means \u0026lt;script src=\u0026quot;example.com/resource\u0026quot;\u0026gt;, \u0026lt;img src=\u0026quot;example.com/resource\u0026quot;\u0026gt;, fetch(), and XHR will all make requests without the SameSite Strict cookies attached. Even if the user clicks on a link to example.com/resource, their cookies are not included.\n  Lax ‚Äì The only difference between Lax and Strict is that Lax mode allows cookies to be added to requests triggered by top-level navigations. This makes Lax cookies much easier to deploy since they won\u0026rsquo;t break incoming links to your application. Unfortunately, an attacker can trigger a top-level navigation via window.open that allows the attacker to maintain a reference to the window object.\n  Considerations #  Strict cookies provide the strongest security guarantees, but it can be very difficult to deploy Strict same-site cookies in an existing application.\nSameSite cookies are neither bulletproof 2 nor can they fix everything. To complement this defense strategy against XS-Leaks, applications should consider implementing other, additional protections. For example, COOP can prevent an attacker from controlling pages using a window reference even if SameSite cookies in Lax mode are used.\nDeployment #  Anyone interested in deploying this mechanism in web applications should take a careful look at this web.dev article.\nReferences #    SameSite cookies explained, link \u0026#x21a9;\u0026#xfe0e;\n Bypass SameSite Cookies Default to Lax and get CSRF, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:42,href:'/docs/attacks/experiments/scroll-to-text-fragment/',title:"Scroll to Text Fragment",section:"Experiments",content:"Scroll to Text Fragment (STTF) is a new web platform feature that allows users to create a link to any part of a web page text. The fragment #:~:text= carries a text snippet that is highlighted and brought into the viewport by the browser. This feature can introduce a new XS-Leak if attackers are able to detect when this behavior occurs. This issue is very similar to the Scroll to CSS Selector XS-Leak.\nExpected \u0026amp; Discussed Issues #  In early discussions regarding the specification of this feature it was shown that several XS-Leaks could be introduced with a na√Øve implementation 1. The specification considers various attack scenarios 2, as does research from Google 3. One possible XS-Leak browsers need to be aware of when implementing this feature is:\n An attacker can, by embedding a page as an iframe, detect whether the page scrolled to the text by listening to the onblur event of the parent document. This approach is similar to the ID Attribute XS-Leak. This scenario is mitigated in the Chrome implementation 4, as it only allows fragment navigation to occur in top-level navigations.  Current Issues #   warning\nThese XS-Leaks require some type of markup injection on the target page.  During the development process of STTF, new attacks and tricks to detect fragment navigation were found. Some of them still work:\n A web page that embeds an attacker-controlled iframe might allow the attacker to determine whether a scroll to the text has occurred. This can be done using the IntersectionObserver API 5 2 3. If a page contains images with Lazy Loading, an attacker can detect if fragment navigation that included an image occurred by checking whether the image was cached in the browser. This works because Lazy Loading images are only fetched (and cached) when they appear in the viewport.   important\nScroll to Text Fragment is only available in Chrome. Its draft specification is under active discussion.   info\nScroll to Text Fragment XS-Leaks allow attackers to extract 1 bit of information at a time, as it\u0026rsquo;s only possible to observe whether a single word exists on the page and only when a user performed some kind of interaction with the page (e.g. a mouse click).  Why is this a problem? #  Attackers can abuse STTF to leak private information about the user that is displayed on a web page.\nCase Scenarios #  A user is logged in to their National Health System website, where it is possible to access information about the user\u0026rsquo;s past diseases and health problems. An attacker can lure the user to one of their pages and use STTF to possibly infer the user\u0026rsquo;s health details. For example, an attacker would find out that the victim suffers from a disease if they detect a page scroll when searching for that disease\u0026rsquo;s name.\nReferences #    Privacy concerns with proposal through inducing network requests, link \u0026#x21a9;\u0026#xfe0e;\n Text Fragments - Security and Privacy, link \u0026#x21a9;\u0026#xfe0e;\n Scroll-to-text Fragment Navigation - Security Issues, link \u0026#x21a9;\u0026#xfe0e;\n Boldly link where no one has linked before: Text Fragments, link \u0026#x21a9;\u0026#xfe0e;\n Possible side-channel information leak using IntersectionObserver, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:43,href:'/docs/attacks/historical/stateful-browser-features/',title:"Stateful Browser Features",section:"Historical",content:"Some browser features/extensions change the way requests are processed, depending on certain website states generated by the browser. Attackers can sometimes observe the whole process and mess with the browser, triggering actions that produce side effects on those states.\nWebKit ‚Äì ITP #  Intelligent Tracking Prevention (ITP) is a privacy feature which is part of WebKit Tracking Prevention technologies. It\u0026rsquo;s a conjunction of several features and aims to prevent a website from tracking a user under a third-party context. Unfortunately, the initial design introduced a new XS-Leak 1, allowing attackers to abuse the states implicitly created by ITP to classify websites as trackers.\nRoot Cause #  To classify whether a website has tracking capabilities, ITP collects statistics on resource loads as well as on user interactions with websites such as clicks, taps, or text entries. Based on the classification of these statistics, ITP gives a strike to a website if it is believed to have tracking capabilities. After 3 strikes, a website is put on a deny list and is treated differently by the browser in future requests.\nIssues #  One of the issues of ITP is that attackers can manipulate it to arbitrarily enforce certain behaviors. For example, an attacker could force ITP to give a strike to a domain and check if the domain entered the deny list. This information could be leveraged in different ways, for example to:\n Leak the user\u0026rsquo;s browsing habits based on how many strikes are necessary for a domain to enter the deny list. Use the deny list to implement an XS-Search attack against a page that includes cross-site resources only when results are present.  Fix #  To fix the issue, ITP now considers every site to be a \u0026ldquo;tracking\u0026rdquo; site by default, instead of relying on classifications. This removes the implicit states which allowed attackers to detect certain ITP behaviors.\nReferences #    Information Leaks via Safari‚Äôs Intelligent Tracking Prevention, link \u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:44,href:'/docs/defenses/design-protections/subresource-protections/',title:"Subresource Protections",section:"Application Design",content:"The fundamental idea behind designing protections for subresources is that subresources cannot be targeted by XS-Leaks if the attacker cannot make them return any user data. If implemented correctly, this approach can be a very strong defense, though it is likely to be tough to implement and could negatively impact the user experience.\n tip\nIt can be very effective to deploy this approach on any specific resources that are known to be especially sensitive to XS-Leaks. But, due to the challenges of deploying this protection universally, applications are encouraged to deploy opt-in web platform security features as the default approach.  Token-Based Protections #  A strong protection for subresources can be achieved by including a user-specific token in every request. This protects against most XS-Leak techniques if implemented correctly. The idea is that in order to verify a request for a resource as being legitimate, a token must be included. This token must be provided to the client in a way that prevents an attacker from including it in their own requests.\n example\nSuppose there is a search bar in an application.\n When the user loads the main page, the server includes a secure token somewhere in the body of the page. When the user searches for something, a request is made to /search?query=\u0026lt;QUERY\u0026gt;\u0026amp;token=\u0026lt;SECURE_TOKEN\u0026gt;. The backend verifies that the provided token is valid for the current user. If it is not valid, the request is rejected.  In this scenario, there is no way for an attacker to trigger any requests to the endpoint because they cannot obtain a valid token for a given user. Note that this relies on it not being possible for an attacker to obtain or forge a token for other users. If they can do so, this approach is not effective.\n This style of protection can be applied to:\n Authenticated subresources such as API endpoints or regular authenticated URLs. While tokens can be used in this case, security mitigations like Same-Site Cookies may be easier to deploy at scale. Unauthenticated subresources such as images can use this protection to prevent some types of Cache Probing Attacks. While this does work, see Cache Protections for other strategies to defend against cache probing attacks.   warning\nImplementing token-based protections might break the ability of users to save or share links (e.g. bookmarks).  User Consent #  Another strong defense is to require user interaction before returning any sensitive data. This ensures that sensitive endpoints cannot be included via script or img tags. For example, Facebook requires user confirmation before viewing search results or private messages. Since attackers cannot simulate this user interaction, they are unable to leak the contents of the search results.\nThis can be a very useful way of protecting especially sensitive endpoints, but note once again that this is likely to be time-consuming to implement.\n"})})()